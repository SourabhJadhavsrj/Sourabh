{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba4df4-3045-49b1-9299-ced1fce14d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61068067\\python_langgraph\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import groq \n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv(find_dotenv())\n",
    "groq.api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm = ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6fde4e-cceb-4426-b770-97ee4b41e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the built-in ToolNode and simply pass a list of tools to initialize it\n",
    "# use the built-in tools_condition as the conditional edge\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([multiply]))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b608c5-0c15-4fb7-aa24-80ce5774fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello What is Generative AI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Generative AI is a type of artificial intelligence that can create new content, such as text, images, music, or even code, based on patterns it has learned from vast amounts of training data. It uses techniques like deep learning to understand the structure and style of existing examples and then generates original outputs that mimic those patterns. For instance, models like GPT (Generative Pre-trained Transformer) can write stories, answer questions, or draft emails, while others like DALL-E can create images from textual descriptions. Its applications range from creative writing to design, gaming, and more. How can I assist you further? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "#messages = [HumanMessage(content=\"Hello, what is 2 multiplied by 2?\")]\n",
    "messages = [HumanMessage(content=\"Hello What is Generative AI\")]\n",
    "messages = graph.invoke({\"messages\": messages})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
